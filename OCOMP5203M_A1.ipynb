{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyshrey/ML/blob/main/OCOMP5203M_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR4bovYL4CJz"
      },
      "source": [
        "## OCOM5203M Assignment 1 - Image Caption Generation [100 marks]\n",
        "\n",
        "The maximum number of marks for each part are shown in the section headers. As indicated in the main heading above, the overall assessment carries a maximum of 100 marks.\n",
        "\n",
        "This summative assessment is weighted 50% of the final grade for the module.\n",
        "\n",
        "### Motivation \n",
        "\n",
        "Through this coursework, you will:\n",
        "\n",
        "> 1. Understand the principles of text pre-processing and vocabulary building.\n",
        "> 2. Gain experience working with an image to text model.\n",
        "> 3. Use and compare two different text similarity metrics for evaluating an image to text model, and understand evaluation challenges.\n",
        "\n",
        "\n",
        "### Setup and resources \n",
        "\n",
        "Having a GPU will speed up the image feature extraction process. If you would like to use a GPU, please refer to the module website for recommended working environments with GPUs.\n",
        "\n",
        "Please implement the coursework using Python and PyTorch, and refer to the notebooks and exercises provided.\n",
        "\n",
        "This coursework will use a subset of the [COCO \"Common Objects in Context\" dataset](https://cocodataset.org/) for image caption generation. COCO contains 330K images, of 80 object categories, and at least five textual reference captions per image. Our subset consists of 5029 of these images, each of which has five or more different descriptions of the salient entities and activities, and we will refer to it as COCO_5029.\n",
        "\n",
        "To download the data:\n",
        "\n",
        "> 1. **Images**: download the zip file \"coco_subset_images.zip (812MB)\" [here](https://leeds365-my.sharepoint.com/:f:/g/personal/busmnom_leeds_ac_uk/EuAH3b6a4g9IjTNhroLLXPoB6ho6cwxYSNh885ZzrktYZA?e=QGSYpf).\n",
        "> 2. **Reference captions**: on the COCO [download page](https://cocodataset.org/#download), download the file named \"2017 Train/Val annotations (241MB)\". \n",
        "> 3. **Image meta data**: as our set is a subset of full COCO dataset, we have created a CSV file containing relevant meta data for our particular subset of images. You can download it also from Drive, \"coco_subset_meta.csv\" at the same link as 1.\n",
        "\n",
        "\n",
        "### Submission\n",
        "\n",
        "Please submit the following:\n",
        "\n",
        "> 1. Your completed Jupyter notebook file, in .ipynb format. **Do not change the file name or the automatic grading will be affected.**\n",
        "> 2. The .html version of your notebook; File > Download as > HTML (.html). Check that all cells have been run and all outputs (including all graphs you would like to be marked) displayed in the .html for marking.\n",
        "\n",
        "\n",
        "Final note:\n",
        "\n",
        "> **Please include in this notebook everything that you would like to be marked, including figures. Under each section, put the relevant code containing your solution. You may re-use functions you defined previously, but any new code must be in the relevant section.** Feel free to add as many code cells as you need under each section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PApXdyNO5hZM"
      },
      "source": [
        "Your student username (for example, ```sc15jb```):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUcMD-ID5hZN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oyl5a1Rn5hZN"
      },
      "source": [
        "Your full name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Otx0SkGQ5hZO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uK5tX4y5hZO"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Feel free to add to this section as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qfkKJeYp5hZP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtKA4RWm5hZP"
      },
      "source": [
        "Detect which device (CPU/GPU) to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8koeiZxo5hZQ",
        "outputId": "7d05955a-f133-4263-87ad-1466b3050ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g-MbowuL5v5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fViBLV05hZQ"
      },
      "source": [
        "The basic principle of our image-to-text model is as pictured in the diagram below, where an Encoder network encodes the input image as a feature vector by providing the outputs of the last fully-connected layer of a pre-trained CNN (we use [ResNet-152](https://arxiv.org/abs/1512.03385)). This pretrained network has been trained on the complete ImageNet dataset and is thus able to recognise common objects. \n",
        "\n",
        "These features are then fed into a Decoder network along with the reference captions. As the image feature dimensions are large and sparse, the Decoder network includes a linear layer which downsizes them, followed by a batch normalisation layer to speed up training. Those resulting features, as well as the reference text captions, are passed into a recurrent network (we will use an RNN). \n",
        "\n",
        "The reference captions used to compute loss are represented as numerical vectors via an embedding layer whose weights are learned during training.\n",
        "\n",
        "![Encoder Decoder](encoder_decoder_diagramv2022.png)\n",
        "\n",
        "The Encoder-Decoder network could be coupled and trained end-to-end, without saving features to disk; however, this requires iterating through the entire image training set during training. We can make the training more efficient by decoupling the networks. \n",
        "\n",
        "We will first extract the feature representations of the images from the Encoder and save them (Part 1). During training of the Decoder (Part 3), we only need to iterate over the image feature data and the reference captions.\n",
        "\n",
        "### Overview\n",
        "\n",
        "> 1. Extracting image features \n",
        "> 2. Text preparation of training and validation data \n",
        "> 3. Training the decoder\n",
        "> 4. Generating predictions on test data\n",
        "> 5. Caption evaluation via BLEU score\n",
        "> 6. Caption evaluation via Cosine similarity\n",
        "> 7. Comparing BLEU and Cosine similarity\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCauGq4N5hZR"
      },
      "source": [
        "## 1 Extracting image features [11 marks]\n",
        "\n",
        "### 1.1 EncoderCNN\n",
        "\n",
        "Read through the template EncoderCNN class below and complete the class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_BjbyYQm5hZR"
      },
      "outputs": [],
      "source": [
        "class EncoderCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"Load the pretrained ResNet-152 and replace top fc layer.\"\"\"\n",
        "        super(EncoderCNN, self).__init__()\n",
        "        resnet = models.resnet152(pretrained=True)\n",
        "        modules = list(resnet.children())[:-1]      # delete the last fc layer.\n",
        "        # print(modules)\n",
        "\n",
        "        # TO COMPLETE\n",
        "        # keep all layers of the pretrained net except the last one\n",
        "\n",
        "        \n",
        "    def forward(self, images):\n",
        "        \"\"\"Extract feature vectors from input images.\"\"\"\n",
        "        with torch.no_grad():\n",
        "          features = self.resnet(images)\n",
        "        features = features.reshape(features.size(0), -1)\n",
        "        features = self.bn(self.linear(features))\n",
        "        return features\n",
        "        # TO COMPLETE\n",
        "        # remember no gradients are needed\n",
        "        # return features "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "134e43b2b54d45e7b74dea1979289395",
            "9a8c1891e70f40eba0c5dd002ad8d80e",
            "0b26c14ae9724844af561cdf8c8e6264",
            "aef137f9ae85403694df037ef06d8154",
            "0e245b0e25f84912b4fc100241210511",
            "2cbc5413acb947aba16198bca13ee5c7",
            "8e34bfcbc094420ba4300ec5f9c4a357",
            "51aff0bb5d1d48df9cfdda9e201eb464",
            "72cedbcd1fb04e3cb03f6593c64effd7",
            "4152b8f51b9a456ab8d2d609e93cd3c1",
            "2e81a80bee1749c4938ded84075591bb"
          ]
        },
        "id": "myxuSAuq5hZS",
        "outputId": "62891571-23b7-4519-f90a-4bc05ce0d309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/230M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "134e43b2b54d45e7b74dea1979289395"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderCNN()"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# instantiate encoder and put into evaluation mode.\n",
        "encoder = EncoderCNN().to(device)\n",
        "encoder.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGbBvd295hZS"
      },
      "source": [
        "### 1.2 Processing the images\n",
        "\n",
        "Pass the images through the ```Encoder``` model, saving the resulting features for each image. You may like to use a ```Dataset``` and ```DataLoader``` to load the data in batches for faster processing, or you may choose to simply read in one image at a time from disk without any loaders.\n",
        "\n",
        "Note that as this is a forward pass only, no gradients are needed. You will need to be able to match each image ID (the image name without file extension) with its features later, so we suggest either saving a dictionary of image ID: image features, or keeping a separate ordered list of image IDs.\n",
        "\n",
        "Use this ImageNet transform provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkW0ym-05hZT"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([ \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(224), \n",
        "    transforms.CenterCrop(224), \n",
        "    transforms.Normalize((0.485, 0.456, 0.406),   # using ImageNet norms\n",
        "                         (0.229, 0.224, 0.225))])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8RQlINq5hZT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCcgyZuA5hZT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p6OXAmo5hZU"
      },
      "outputs": [],
      "source": [
        "# torch.save(features, 'features.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfR--uYXHdIi"
      },
      "source": [
        "## 2 Text preparation [23 marks]\n",
        "\n",
        "\n",
        "### 2.1 Build the caption dataset\n",
        "\n",
        "All our selected COCO_5029 images are from the official 2017 train set.\n",
        "\n",
        "The ```coco_subset_meta.csv``` file includes the image filenames and unique IDs of all the images in our subset. The ```id``` column corresponds to each unique image ID.\n",
        "\n",
        "The COCO dataset includes many different types of annotations: bounding boxes, keypoints, reference captions, and more. We are interested in the captioning labels. Open ```captions_train2017.json``` from the zip file downloaded from the COCO website. You are welcome to come up with your own way of doing it, but we recommend using the ```json``` package to initially inspect the data, then the ```pandas``` package to look at the annotations (if you read in the file as ```data```, then you can access the annotations dictionary as ```data['annotations']```).\n",
        "\n",
        "Use ```coco_subset_meta.csv``` to cross-reference with the annotations from ```captions_train2017.json``` to get all the reference captions for each image in COCO_5029.\n",
        "\n",
        "For example, you may end up with data looking like this (this is a ```pandas``` DataFrame, but it could also be several lists, or some other data structure/s):\n",
        "\n",
        "<img src=\"df_caption_set.png\" alt=\"images matched to caption\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DUtQYH8S9V6O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPWN96uh5hZV"
      },
      "outputs": [],
      "source": [
        "#connecting to google drive to get the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ihn6riA5hZV",
        "outputId": "76dadae9-387d-4333-db9f-2aca30b320db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "annotation_path = '/content/drive/MyDrive/Leeds MSc/DL/annotations'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "meta_file = pd.read_csv('/content/drive/MyDrive/Leeds MSc/DL/coco_subset_meta.csv')"
      ],
      "metadata": {
        "id": "eRnyf4Xq9PGR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = meta_file[['file_name','id']]\n",
        "df.rename(columns = {'id':'image_id'}, inplace = True)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "0bZjVzuMKTn6",
        "outputId": "29b86315-e529-48ab-8d76-e8d538cc210f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:5039: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().rename(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          file_name  image_id\n",
              "0  000000262145.jpg    262145\n",
              "1  000000262146.jpg    262146\n",
              "2  000000524291.jpg    524291\n",
              "3  000000262148.jpg    262148\n",
              "4  000000393223.jpg    393223"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06781d2d-18f9-48ed-bafd-9b7202f082f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>image_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000262145.jpg</td>\n",
              "      <td>262145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000000262146.jpg</td>\n",
              "      <td>262146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000000524291.jpg</td>\n",
              "      <td>524291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000000262148.jpg</td>\n",
              "      <td>262148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000000393223.jpg</td>\n",
              "      <td>393223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06781d2d-18f9-48ed-bafd-9b7202f082f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06781d2d-18f9-48ed-bafd-9b7202f082f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06781d2d-18f9-48ed-bafd-9b7202f082f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['image_id'] == 203564]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "YZzJiEG5ZkW_",
        "outputId": "132dbc15-f66a-4838-d572-11cb842e1793"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [file_name, image_id]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a71e6d7-008f-46e8-a914-b5cf2256f2f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>image_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a71e6d7-008f-46e8-a914-b5cf2256f2f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a71e6d7-008f-46e8-a914-b5cf2256f2f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a71e6d7-008f-46e8-a914-b5cf2256f2f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "  \n",
        "# Opening JSON file\n",
        "f = open('/content/drive/MyDrive/Leeds MSc/DL/annotations/captions_train2017.json')\n",
        "  \n",
        "# returns JSON object as \n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "\n",
        "print(data.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B59YxE0U9PO7",
        "outputId": "ee178684-be26-4596-c1b7-7417a5f840ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['info', 'licenses', 'images', 'annotations'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann_list = data['annotations']\n",
        "ann_df = pd.DataFrame.from_records(ann_list)\n",
        "ann_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03TW4oL39PSC",
        "outputId": "fc6d118b-3b82-4918-893d-effd8a2c8a96"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(591753, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ann_df[ann_df['image_id']== 203564]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "rchEERCcBuqv",
        "outputId": "7ac64319-ba42-47cf-c785-fb3deb25be17"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     image_id    id                                            caption\n",
              "0      203564    37  A bicycle replica with a clock as the front wh...\n",
              "8      203564   181                    The bike has a clock as a tire.\n",
              "19     203564   478  A black metal bicycle with a clock inside the ...\n",
              "237    203564  6637  A bicycle figurine in which the front wheel is...\n",
              "246    203564  6802  A clock with the appearance of the wheel of a ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0d91bd4-806a-47d7-a838-cf1bdc93e514\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>id</th>\n",
              "      <th>caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>203564</td>\n",
              "      <td>37</td>\n",
              "      <td>A bicycle replica with a clock as the front wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>203564</td>\n",
              "      <td>181</td>\n",
              "      <td>The bike has a clock as a tire.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>203564</td>\n",
              "      <td>478</td>\n",
              "      <td>A black metal bicycle with a clock inside the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>203564</td>\n",
              "      <td>6637</td>\n",
              "      <td>A bicycle figurine in which the front wheel is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>203564</td>\n",
              "      <td>6802</td>\n",
              "      <td>A clock with the appearance of the wheel of a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0d91bd4-806a-47d7-a838-cf1bdc93e514')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0d91bd4-806a-47d7-a838-cf1bdc93e514 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0d91bd4-806a-47d7-a838-cf1bdc93e514');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_list = data['images']\n",
        "image_df = pd.DataFrame.from_records(image_list)"
      ],
      "metadata": {
        "id": "Ak0nqwH_9PYS"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuucjYnBCTyQ",
        "outputId": "f87015f7-1c88-4e6a-a77e-a5e15021e9c8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(118287, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.merge(ann_df, image_df, how='inner', left_on='image_id', right_on='id')\n"
      ],
      "metadata": {
        "id": "x8_h3eqvDhhy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3[df3['image_id']== 203564]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "9x5_D2XSDzQp",
        "outputId": "1962d48a-a428-4a22-a6ee-fa0ff0a87732"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   image_id  id_x                                            caption  license  \\\n",
              "0    203564    37  A bicycle replica with a clock as the front wh...        4   \n",
              "1    203564   181                    The bike has a clock as a tire.        4   \n",
              "2    203564   478  A black metal bicycle with a clock inside the ...        4   \n",
              "3    203564  6637  A bicycle figurine in which the front wheel is...        4   \n",
              "4    203564  6802  A clock with the appearance of the wheel of a ...        4   \n",
              "\n",
              "          file_name                                           coco_url  \\\n",
              "0  000000203564.jpg  http://images.cocodataset.org/train2017/000000...   \n",
              "1  000000203564.jpg  http://images.cocodataset.org/train2017/000000...   \n",
              "2  000000203564.jpg  http://images.cocodataset.org/train2017/000000...   \n",
              "3  000000203564.jpg  http://images.cocodataset.org/train2017/000000...   \n",
              "4  000000203564.jpg  http://images.cocodataset.org/train2017/000000...   \n",
              "\n",
              "   height  width        date_captured  \\\n",
              "0     400    400  2013-11-15 03:12:47   \n",
              "1     400    400  2013-11-15 03:12:47   \n",
              "2     400    400  2013-11-15 03:12:47   \n",
              "3     400    400  2013-11-15 03:12:47   \n",
              "4     400    400  2013-11-15 03:12:47   \n",
              "\n",
              "                                          flickr_url    id_y  \n",
              "0  http://farm8.staticflickr.com/7366/9643253026_...  203564  \n",
              "1  http://farm8.staticflickr.com/7366/9643253026_...  203564  \n",
              "2  http://farm8.staticflickr.com/7366/9643253026_...  203564  \n",
              "3  http://farm8.staticflickr.com/7366/9643253026_...  203564  \n",
              "4  http://farm8.staticflickr.com/7366/9643253026_...  203564  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c505c7db-1147-4c8b-959a-073df1394e9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>id_x</th>\n",
              "      <th>caption</th>\n",
              "      <th>license</th>\n",
              "      <th>file_name</th>\n",
              "      <th>coco_url</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>date_captured</th>\n",
              "      <th>flickr_url</th>\n",
              "      <th>id_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>203564</td>\n",
              "      <td>37</td>\n",
              "      <td>A bicycle replica with a clock as the front wh...</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>203564</td>\n",
              "      <td>181</td>\n",
              "      <td>The bike has a clock as a tire.</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>203564</td>\n",
              "      <td>478</td>\n",
              "      <td>A black metal bicycle with a clock inside the ...</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>203564</td>\n",
              "      <td>6637</td>\n",
              "      <td>A bicycle figurine in which the front wheel is...</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>203564</td>\n",
              "      <td>6802</td>\n",
              "      <td>A clock with the appearance of the wheel of a ...</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c505c7db-1147-4c8b-959a-073df1394e9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c505c7db-1147-4c8b-959a-073df1394e9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c505c7db-1147-4c8b-959a-073df1394e9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "36r6IiK8Dqil",
        "outputId": "6b8cce42-081d-4233-d9f4-433c0428098d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        image_id    id_x                                            caption  \\\n",
              "0         203564      37  A bicycle replica with a clock as the front wh...   \n",
              "1         203564     181                    The bike has a clock as a tire.   \n",
              "2         203564     478  A black metal bicycle with a clock inside the ...   \n",
              "3         203564    6637  A bicycle figurine in which the front wheel is...   \n",
              "4         203564    6802  A clock with the appearance of the wheel of a ...   \n",
              "...          ...     ...                                                ...   \n",
              "591748    180285  829395       A couple of women with some stuffed animals.   \n",
              "591749    180285  829607     Fans pose with stuffed animals at an ice rink.   \n",
              "591750    180285  829636  Two women smiling together, one holds a stuffe...   \n",
              "591751    180285  829653  Two women smile for the camea while posing iwt...   \n",
              "591752    180285  829665       Two women sit and pose with stuffed animals.   \n",
              "\n",
              "        license         file_name  \\\n",
              "0             4  000000203564.jpg   \n",
              "1             4  000000203564.jpg   \n",
              "2             4  000000203564.jpg   \n",
              "3             4  000000203564.jpg   \n",
              "4             4  000000203564.jpg   \n",
              "...         ...               ...   \n",
              "591748        2  000000180285.jpg   \n",
              "591749        2  000000180285.jpg   \n",
              "591750        2  000000180285.jpg   \n",
              "591751        2  000000180285.jpg   \n",
              "591752        2  000000180285.jpg   \n",
              "\n",
              "                                                 coco_url  height  width  \\\n",
              "0       http://images.cocodataset.org/train2017/000000...     400    400   \n",
              "1       http://images.cocodataset.org/train2017/000000...     400    400   \n",
              "2       http://images.cocodataset.org/train2017/000000...     400    400   \n",
              "3       http://images.cocodataset.org/train2017/000000...     400    400   \n",
              "4       http://images.cocodataset.org/train2017/000000...     400    400   \n",
              "...                                                   ...     ...    ...   \n",
              "591748  http://images.cocodataset.org/train2017/000000...     480    640   \n",
              "591749  http://images.cocodataset.org/train2017/000000...     480    640   \n",
              "591750  http://images.cocodataset.org/train2017/000000...     480    640   \n",
              "591751  http://images.cocodataset.org/train2017/000000...     480    640   \n",
              "591752  http://images.cocodataset.org/train2017/000000...     480    640   \n",
              "\n",
              "              date_captured  \\\n",
              "0       2013-11-15 03:12:47   \n",
              "1       2013-11-15 03:12:47   \n",
              "2       2013-11-15 03:12:47   \n",
              "3       2013-11-15 03:12:47   \n",
              "4       2013-11-15 03:12:47   \n",
              "...                     ...   \n",
              "591748  2013-11-24 15:20:21   \n",
              "591749  2013-11-24 15:20:21   \n",
              "591750  2013-11-24 15:20:21   \n",
              "591751  2013-11-24 15:20:21   \n",
              "591752  2013-11-24 15:20:21   \n",
              "\n",
              "                                               flickr_url    id_y  \n",
              "0       http://farm8.staticflickr.com/7366/9643253026_...  203564  \n",
              "1       http://farm8.staticflickr.com/7366/9643253026_...  203564  \n",
              "2       http://farm8.staticflickr.com/7366/9643253026_...  203564  \n",
              "3       http://farm8.staticflickr.com/7366/9643253026_...  203564  \n",
              "4       http://farm8.staticflickr.com/7366/9643253026_...  203564  \n",
              "...                                                   ...     ...  \n",
              "591748  http://farm3.staticflickr.com/2554/4165824109_...  180285  \n",
              "591749  http://farm3.staticflickr.com/2554/4165824109_...  180285  \n",
              "591750  http://farm3.staticflickr.com/2554/4165824109_...  180285  \n",
              "591751  http://farm3.staticflickr.com/2554/4165824109_...  180285  \n",
              "591752  http://farm3.staticflickr.com/2554/4165824109_...  180285  \n",
              "\n",
              "[591753 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0be428ba-c5c0-4f49-9dac-7db6746a4b0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>id_x</th>\n",
              "      <th>caption</th>\n",
              "      <th>license</th>\n",
              "      <th>file_name</th>\n",
              "      <th>coco_url</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>date_captured</th>\n",
              "      <th>flickr_url</th>\n",
              "      <th>id_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>203564</td>\n",
              "      <td>37</td>\n",
              "      <td>A bicycle replica with a clock as the front wh...</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>203564</td>\n",
              "      <td>181</td>\n",
              "      <td>The bike has a clock as a tire.</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>203564</td>\n",
              "      <td>478</td>\n",
              "      <td>A black metal bicycle with a clock inside the ...</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>203564</td>\n",
              "      <td>6637</td>\n",
              "      <td>A bicycle figurine in which the front wheel is...</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>203564</td>\n",
              "      <td>6802</td>\n",
              "      <td>A clock with the appearance of the wheel of a ...</td>\n",
              "      <td>4</td>\n",
              "      <td>000000203564.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>400</td>\n",
              "      <td>400</td>\n",
              "      <td>2013-11-15 03:12:47</td>\n",
              "      <td>http://farm8.staticflickr.com/7366/9643253026_...</td>\n",
              "      <td>203564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591748</th>\n",
              "      <td>180285</td>\n",
              "      <td>829395</td>\n",
              "      <td>A couple of women with some stuffed animals.</td>\n",
              "      <td>2</td>\n",
              "      <td>000000180285.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>480</td>\n",
              "      <td>640</td>\n",
              "      <td>2013-11-24 15:20:21</td>\n",
              "      <td>http://farm3.staticflickr.com/2554/4165824109_...</td>\n",
              "      <td>180285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591749</th>\n",
              "      <td>180285</td>\n",
              "      <td>829607</td>\n",
              "      <td>Fans pose with stuffed animals at an ice rink.</td>\n",
              "      <td>2</td>\n",
              "      <td>000000180285.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>480</td>\n",
              "      <td>640</td>\n",
              "      <td>2013-11-24 15:20:21</td>\n",
              "      <td>http://farm3.staticflickr.com/2554/4165824109_...</td>\n",
              "      <td>180285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591750</th>\n",
              "      <td>180285</td>\n",
              "      <td>829636</td>\n",
              "      <td>Two women smiling together, one holds a stuffe...</td>\n",
              "      <td>2</td>\n",
              "      <td>000000180285.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>480</td>\n",
              "      <td>640</td>\n",
              "      <td>2013-11-24 15:20:21</td>\n",
              "      <td>http://farm3.staticflickr.com/2554/4165824109_...</td>\n",
              "      <td>180285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591751</th>\n",
              "      <td>180285</td>\n",
              "      <td>829653</td>\n",
              "      <td>Two women smile for the camea while posing iwt...</td>\n",
              "      <td>2</td>\n",
              "      <td>000000180285.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>480</td>\n",
              "      <td>640</td>\n",
              "      <td>2013-11-24 15:20:21</td>\n",
              "      <td>http://farm3.staticflickr.com/2554/4165824109_...</td>\n",
              "      <td>180285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>591752</th>\n",
              "      <td>180285</td>\n",
              "      <td>829665</td>\n",
              "      <td>Two women sit and pose with stuffed animals.</td>\n",
              "      <td>2</td>\n",
              "      <td>000000180285.jpg</td>\n",
              "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
              "      <td>480</td>\n",
              "      <td>640</td>\n",
              "      <td>2013-11-24 15:20:21</td>\n",
              "      <td>http://farm3.staticflickr.com/2554/4165824109_...</td>\n",
              "      <td>180285</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>591753 rows  11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0be428ba-c5c0-4f49-9dac-7db6746a4b0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0be428ba-c5c0-4f49-9dac-7db6746a4b0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0be428ba-c5c0-4f49-9dac-7db6746a4b0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_df[image_df['id']== 203564]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "0eRRhDUIC81V",
        "outputId": "57e100bc-63d0-4511-a78e-1322e937f94d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [license, file_name, coco_url, height, width, date_captured, flickr_url, id]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a07d509b-3853-4812-8f09-ab8cd0485ec5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>license</th>\n",
              "      <th>file_name</th>\n",
              "      <th>coco_url</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>date_captured</th>\n",
              "      <th>flickr_url</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a07d509b-3853-4812-8f09-ab8cd0485ec5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a07d509b-3853-4812-8f09-ab8cd0485ec5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a07d509b-3853-4812-8f09-ab8cd0485ec5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_df\n",
        "# image_df.rename(columns = {'id':'image_id'}, inplace = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BGkQjMHtcDy5",
        "outputId": "6b67a99f-7ea8-4f34-e4b2-0471ba2922f5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          file_name      id\n",
              "0  000000391895.jpg  391895\n",
              "1  000000522418.jpg  522418\n",
              "2  000000184613.jpg  184613\n",
              "3  000000318219.jpg  318219\n",
              "4  000000554625.jpg  554625"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d42712b-bca6-4ab4-beb2-c0b10ad41810\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000391895.jpg</td>\n",
              "      <td>391895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000000522418.jpg</td>\n",
              "      <td>522418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000000184613.jpg</td>\n",
              "      <td>184613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000000318219.jpg</td>\n",
              "      <td>318219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000000554625.jpg</td>\n",
              "      <td>554625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d42712b-bca6-4ab4-beb2-c0b10ad41810')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d42712b-bca6-4ab4-beb2-c0b10ad41810 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d42712b-bca6-4ab4-beb2-c0b10ad41810');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "If data[annotation][image_id] == data[images][id] then:\n",
        "Get file_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "kigN_qtwSXxx",
        "outputId": "36fb58a6-c298-4561-ae87-6a47b58f69e6"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [image_id, caption, file_name]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35cbc924-a9d4-4809-94b4-3b506352ef66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>caption</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35cbc924-a9d4-4809-94b4-3b506352ef66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-35cbc924-a9d4-4809-94b4-3b506352ef66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-35cbc924-a9d4-4809-94b4-3b506352ef66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compareColumn = []\n",
        "for index, row in ann_df.iterrows():\n",
        "  image_dfRow = image_df[image_df[\"id\"] == row[\"image_id\"]]\n",
        "  if image_dfRow.shape[0] == 0:\n",
        "    compareColumn.append(\"ID not available\")\n",
        "ann_df[\"compare\"] = compareColumn\n",
        "ann_df.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uVBYUTVC-c-s",
        "outputId": "dda172b8-d9e4-4dcd-bab6-6b8945145bf2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   image_id   id                                            caption  \\\n",
              "0    203564   37  A bicycle replica with a clock as the front wh...   \n",
              "1    322141   49  A room with blue walls and a white sink and door.   \n",
              "2     16977   89  A car that seems to be parked illegally behind...   \n",
              "3    106140   98  A large passenger airplane flying through the ...   \n",
              "4    106140  101  There is a GOL plane taking off in a partly cl...   \n",
              "\n",
              "            compare  \n",
              "0  ID not available  \n",
              "1  ID not available  \n",
              "2  ID not available  \n",
              "3  ID not available  \n",
              "4  ID not available  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3cd188ca-ed8a-464d-a637-41e8163e5769\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>id</th>\n",
              "      <th>caption</th>\n",
              "      <th>compare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>203564</td>\n",
              "      <td>37</td>\n",
              "      <td>A bicycle replica with a clock as the front wh...</td>\n",
              "      <td>ID not available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>322141</td>\n",
              "      <td>49</td>\n",
              "      <td>A room with blue walls and a white sink and door.</td>\n",
              "      <td>ID not available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16977</td>\n",
              "      <td>89</td>\n",
              "      <td>A car that seems to be parked illegally behind...</td>\n",
              "      <td>ID not available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>106140</td>\n",
              "      <td>98</td>\n",
              "      <td>A large passenger airplane flying through the ...</td>\n",
              "      <td>ID not available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>106140</td>\n",
              "      <td>101</td>\n",
              "      <td>There is a GOL plane taking off in a partly cl...</td>\n",
              "      <td>ID not available</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cd188ca-ed8a-464d-a637-41e8163e5769')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cd188ca-ed8a-464d-a637-41e8163e5769 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cd188ca-ed8a-464d-a637-41e8163e5769');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from torch.utils.data import DataLoader, IterableDataset\n",
        "\n",
        "\n",
        "class JsonDataset(IterableDataset):\n",
        "    def __init__(self, files):\n",
        "        self.files = files\n",
        "\n",
        "    def __iter__(self):\n",
        "        for json_file in self.files:\n",
        "            with open(json_file) as f:\n",
        "                for sample_line in f:\n",
        "                    sample = json.loads(sample_line)\n",
        "                    yield sample['annotations'], sample['images']\n",
        "\n",
        "dataset = JsonDataset(['/content/drive/MyDrive/Leeds MSc/DL/annotations/captions_train2017.json'])\n",
        "dataloader = DataLoader(dataset, batch_size=32)\n",
        "\n",
        "# for batch in dataloader:\n",
        "#     print(batch)"
      ],
      "metadata": {
        "id": "GZ0kFkU4_iZU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE6NX0Ux_idu",
        "outputId": "5c6f3d54-fdcf-45f1-9868-a79feb9dda67"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5Tt7IM25hZV"
      },
      "source": [
        "### 2.2 Clean the captions\n",
        "\n",
        "Create a cleaned version of each caption. If using dataframes, we suggest saving the cleaned captions in a new column; otherwise, if you are storing your data in some other way, create data structures as needed. \n",
        "\n",
        "**A cleaned caption should be all lowercase, and consist of only alphabet characters.**\n",
        "\n",
        "Print out 10 original captions next to their cleaned versions to facilitate marking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PFXEvpE5hZW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8oTXenS5hZW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04Umb4VT5hZW"
      },
      "source": [
        "### 2.3  Split the data\n",
        "\n",
        "Split the data 70/10/20% into train/validation/test sets. **Be sure that each unique image (and all corresponding captions) only appear in a single set.**\n",
        "\n",
        "We provide the function below which, given a list of unique image IDs and a 3-split ratio, shuffles and returns  a split of the image IDs.\n",
        "\n",
        "If using a dataframe, ```df['image_id'].unique()``` will return the list of unique image IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rue1LnaX5hZW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "def split_ids(image_id_list, train=.7, valid=0.1, test=0.2):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image_id_list (int list): list of unique image ids\n",
        "        train (float): train split size (between 0 - 1)\n",
        "        valid (float): valid split size (between 0 - 1)\n",
        "        test (float): test split size (between 0 - 1)\n",
        "    \"\"\"\n",
        "    list_copy = image_id_list.copy()\n",
        "    random.shuffle(list_copy)\n",
        "    \n",
        "    train_size = math.floor(len(list_copy) * train)\n",
        "    valid_size = math.floor(len(list_copy) * valid)\n",
        "    \n",
        "    return list_copy[:train_size], list_copy[train_size:(train_size + valid_size)], list_copy[(train_size + valid_size):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6XWiygT5hZX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggrsNGPk5hZX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3msz-_a5hZX"
      },
      "source": [
        "### 2.3 Building the vocabulary\n",
        "\n",
        "The vocabulary consists of all the possible words which can be used - both as input into the model, and as output predictions, and we will build it using the cleaned words found in the reference captions from the training set. In the vocabulary each unique word is mapped to a unique integer (a Python ```dictionary``` object).\n",
        "\n",
        "A ```Vocabulary``` object is provided for you below to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZDBfoa55hZY"
      },
      "outputs": [],
      "source": [
        "class Vocabulary(object):\n",
        "    \"\"\" Simple vocabulary wrapper which maps every unique word to an integer ID. \"\"\"\n",
        "    def __init__(self):\n",
        "        # intially, set both the IDs and words to dictionaries with special tokens\n",
        "        self.word2idx = {'<pad>': 0, '<unk>': 1, '<end>': 2}\n",
        "        self.idx2word = {0: '<pad>', 1: '<unk>', 2: '<end>'}\n",
        "        self.idx = 3\n",
        "\n",
        "    def add_word(self, word):\n",
        "        # if the word does not already exist in the dictionary, add it\n",
        "        if not word in self.word2idx:\n",
        "            self.word2idx[word] = self.idx\n",
        "            self.idx2word[self.idx] = word\n",
        "            # increment the ID for the next word\n",
        "            self.idx += 1\n",
        "\n",
        "    def __call__(self, word):\n",
        "        # if we try to access a word not in the dictionary, return the id for <unk>\n",
        "        if not word in self.word2idx:\n",
        "            return self.word2idx['<unk>']\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.word2idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mxFuzhj5hZY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvs5b6M95hZY"
      },
      "source": [
        "Collect all words from the cleaned captions in the **training and validation sets**, ignoring any words which appear 3 times or less; this should leave you with roughly 2200 words (plus or minus is fine). As the vocabulary size affects the embedding layer dimensions, it is better not to add the very infrequently used words to the vocabulary.\n",
        "\n",
        "Create an instance of the ```Vocabulary()``` object and add all your words to it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bPL4WQg5hZY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mzn9S_cv5hZY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uis6nR9N5hZZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYx-qVAX5hZZ"
      },
      "source": [
        "### 2.4 The Dataset and DataLoader\n",
        "\n",
        "Create a PyTorch ```Dataset``` class and a corresponding ```DataLoader``` for the inputs to the decoder. Create three sets: one each for training, validation, and test. Set ```shuffle=True``` for the training set DataLoader.\n",
        "\n",
        "The ```Dataset``` function ```__getitem__(self, index)``` should return three Tensors:\n",
        "\n",
        ">1. A Tensor of image features, dimension (1, 2048).\n",
        ">2. A Tensor of integer word ids representing the reference caption; use your ```Vocabulary``` object to convert each word in the caption to a word ID. Be sure to add the word ID for the ```<end>``` token at the end of each caption, then fill in the the rest of the caption with the ```<pad>``` token so that each caption has uniform lenth (max sequence length) of **47**.\n",
        ">3. A Tensor of integers representing the true lengths of every caption in the batch (include the ```<end>``` token in the count).\n",
        "\n",
        "\n",
        "Note that as each unique image has five or more (say, ```n```) reference captions, each image feature will appear ```n``` times, once in each unique (feature, caption) pair."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkIvy-SM5hZZ"
      },
      "outputs": [],
      "source": [
        "class COCO_Subset(Dataset):\n",
        "    \"\"\" COCO subset custom dataset, compatible with torch.utils.data.DataLoader. \"\"\"\n",
        "    \n",
        "    def __init__(self, df, features, vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            df: (dataframe or some other data structure/s you may prefer to use)\n",
        "            features: image features\n",
        "            vocab: vocabulary wrapper\n",
        "           \n",
        "        \"\"\"\n",
        "        \n",
        "        # TO COMPLETE\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \"\"\" Returns one data tuple (feature [1, 2048], target caption of word IDs [1, 47], and integer true caption length) \"\"\"   \n",
        "        \n",
        "       # TO COMPLETE\n",
        "    \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgkEEmPA5hZZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2S66p-6d5hZZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2pYh9Rf5hZZ"
      },
      "source": [
        "Load one batch of the training set and print out the shape of each returned Tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVEaAwCH5hZZ"
      },
      "outputs": [],
      "source": [
        "# train_iter = iter(train_loader)\n",
        "# features, captions, lengths = train_iter.next()\n",
        "# print(features.shape)\n",
        "# print(captions.shape)\n",
        "# print(lengths.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ3naDXD5hZa"
      },
      "source": [
        "## 3 Train DecoderRNN [15 marks]\n",
        "\n",
        "### 3.1 Define the encoder model\n",
        "\n",
        "Read through the ```DecoderRNN``` model below. First, complete the decoder by adding an ```rnn``` layer to the decoder where indicated, using [the PyTorch API as reference](https://pytorch.org/docs/stable/nn.html#rnn).\n",
        "\n",
        "Keep all the default parameters except for ```batch_first```, which you may set to True.\n",
        "\n",
        "In particular, understand the meaning of ```pack_padded_sequence()``` as used in ```forward()```. Refer to the [PyTorch ```pack_padded_sequence()``` documentation](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFbFxvIU5hZa"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size=256, hidden_size=512, num_layers=1, max_seq_length=47):\n",
        "        \"\"\"Set the hyper-parameters and build the layers.\"\"\"\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        # we want a specific output size, which is the size of our embedding, so\n",
        "        # we feed our extracted features from the last fc layer (dimensions 1 x 2048)\n",
        "        # into a Linear layer to resize\n",
        "        self.resize = nn.Linear(2048, embed_size)\n",
        "        \n",
        "        # batch normalisation helps to speed up training\n",
        "        self.bn = nn.BatchNorm1d(embed_size, momentum=0.01)\n",
        "\n",
        "        # What is an embedding layer?\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        # TO COMPLETE\n",
        "        # self.rnn = \n",
        "\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "        self.max_seq_length = max_seq_length\n",
        "        \n",
        "\n",
        "    def forward(self, features, captions, lengths):\n",
        "        \"\"\"Decode image feature vectors and generates captions.\"\"\"\n",
        "        embeddings = self.embed(captions)\n",
        "        im_features = self.resize(features)\n",
        "        im_features = self.bn(im_features)\n",
        "        \n",
        "        embeddings = torch.cat((im_features.unsqueeze(1), embeddings), 1)\n",
        "    \n",
        "        packed = pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False) \n",
        "        # pack_padded_sequence returns a PackedSequence object, which contains two items: \n",
        "        # the packed data (data cut off at its true length and flattened into one list), and \n",
        "        # the batch_sizes, or the number of elements at each sequence step in the batch.\n",
        "        # For instance, given data [a, b, c] and [x] the PackedSequence would contain data \n",
        "        # [a, x, b, c] with batch_sizes=[2,1,1].\n",
        "        \n",
        "        hiddens, _ = self.rnn(packed)\n",
        "        outputs = self.linear(hiddens.data) # hiddens[0]\n",
        "        return outputs\n",
        "    \n",
        "    \n",
        "    def sample(self, features, states=None):\n",
        "        \"\"\"Generate captions for given image features using greedy search.\"\"\"\n",
        "        sampled_ids = []\n",
        "\n",
        "        inputs = self.bn(self.resize(features)).unsqueeze(1)\n",
        "        for i in range(self.max_seq_length):\n",
        "            hiddens, states = self.rnn(inputs, states)  # hiddens: (batch_size, 1, hidden_size)\n",
        "            outputs = self.linear(hiddens.squeeze(1))   # outputs:  (batch_size, vocab_size)\n",
        "            _, predicted = outputs.max(1)               # predicted: (batch_size)\n",
        "            sampled_ids.append(predicted)\n",
        "            inputs = self.embed(predicted)              # inputs: (batch_size, embed_size)\n",
        "            inputs = inputs.unsqueeze(1)                # inputs: (batch_size, 1, embed_size)\n",
        "        sampled_ids = torch.stack(sampled_ids, 1)       # sampled_ids: (batch_size, max_seq_length)\n",
        "        return sampled_ids\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCLsCeEB5hZa"
      },
      "outputs": [],
      "source": [
        "# instantiate decoder\n",
        "decoder = DecoderRNN(len(vocab)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ga9bFPnu5hZa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll5JI91J5hZb"
      },
      "source": [
        "### 3.2 Train the decoder\n",
        "\n",
        "Train the decoder by passing the features, reference captions, and targets to the decoder, then computing loss based on the outputs and the targets. Note that when passing the targets and model outputs to the loss function, the targets will also need to be formatted using ```pack_padded_sequence()```.\n",
        "\n",
        "We recommend a batch size of around 64 (though feel free to adjust as necessary for your hardware).\n",
        "\n",
        "**We strongly recommend saving a checkpoint of your trained model after training so you don't need to re-train multiple times.**\n",
        "\n",
        "Display a graph of training and validation loss over epochs to justify your stopping point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmVVrKd45hZb"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ib0LCGj_5hZb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evsh9miO5hZb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUqfK8QI5hZb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXzlLbstCE7f"
      },
      "source": [
        "## 4 Generate predictions on test data [8 marks]\n",
        "\n",
        "Display 5 sample test images containing different objects, along with your models generated captions and all the reference captions for each.\n",
        "\n",
        "> Remember that everything **displayed** in the submitted notebook and .html file will be marked, so be sure to run all relevant cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-O-Vz2l5hZb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBU8-UsD5hZc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7np733bd5hZc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVfEgbC4I_dE"
      },
      "source": [
        "## 5 Caption evaluation using BLEU score [10 marks]\n",
        "\n",
        "There are different methods for measuring the performance of image to text models. We will evaluate our model by measuring the text similarity between the generated caption and the reference captions, using two commonly used methods. Ther first method is known as *Bilingual Evaluation Understudy (BLEU)*.\n",
        "\n",
        "###  5.1 BLEU score\n",
        "\n",
        "\n",
        "One common way of comparing a generated text to a reference text is using BLEU. This article gives a good intuition to how the BLEU score is computed: https://machinelearningmastery.com/calculate-bleu-score-for-text-python/, and you may find an implementation online to use. One option is the NLTK implementation `nltk.translate.bleu_score` here: https://www.nltk.org/api/nltk.translate.bleu_score.html\n",
        "\n",
        "\n",
        "> **Tip:** BLEU scores can be weighted by ith-gram. Check that your scores make sense; and feel free to use a weighting that best matches the data. We will not be looking for specific score ranges; rather we will check that the scores are reasonable and meaningful given the captions.\n",
        "\n",
        "Write the code to evaluate the trained model on the complete test set and calculate the BLEU score using the predictions, compared against all five references captions. \n",
        "\n",
        "Display a histogram of the distribution of scores over the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xypfUN7y4CKI"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAXrOzjE5hZc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPnCbFp25hZc"
      },
      "source": [
        "### 5.2 BLEU score examples\n",
        "\n",
        "Find one sample with high BLEU score and one with a low score, and display the model's predicted sentences, the BLEU scores, and the 5 reference captions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3RqgXUq5hZc"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIuM7H5Q5hZc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VQKNo384CKP"
      },
      "source": [
        "## 6 Caption evaluation using cosine similarity [12 marks]\n",
        "\n",
        "###  6.1 Cosine similarity\n",
        "\n",
        "The cosine similarity measures the cosine of the angle between two vectors in n-dimensional space. The smaller the angle, the greater the similarity.\n",
        "\n",
        "To use the cosine similarity to measure the similarity between the generated caption and the reference captions: \n",
        "\n",
        "* Find the embedding vector of each word in the caption \n",
        "* Compute the average vector for each caption \n",
        "* Compute the cosine similarity score between the average vector of the generated caption and average vector of each reference caption\n",
        "* Compute the average of these scores \n",
        "\n",
        "Calculate the cosine similarity using the model's predictions over the whole test set. \n",
        "\n",
        "Display a histogram of the distribution of scores over the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4kaOxNY5hZd"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aECpoyvk5hZd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19TErXv45hZd"
      },
      "source": [
        "#### 6.2 Cosine similarity examples \n",
        "\n",
        "Find one sample with high cosine similarity score and one with a low score, and display the model's predicted sentences, the cosine similarity scores, and the 5 reference captions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRINvQc-5hZd"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbVvSjcW5hZd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDmwrp-w4CKR"
      },
      "source": [
        "## 7 Comparing BLEU and Cosine similarity [16 marks]\n",
        "\n",
        "### 7.1 Test set distribution of scores\n",
        "\n",
        "Compare the models performance on the test set evaluated using BLEU and cosine similarity and discuss some weaknesses and strengths of each method (explain in words, in a text box below). \n",
        "\n",
        "Please note, to compare the average test scores, you need to rescale the Cosine similarity scores [-1 to 1] to match the range of BLEU method [0.0 - 1.0]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2O8TZG74CKS"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qigb0A9F4CKV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2fHKGoo5hZe"
      },
      "source": [
        " ### 7.2 Analysis of individual examples\n",
        " \n",
        "Find and display one example where both methods give similar scores and another example where they do not and discuss. Include both scores, predicted captions, and reference captions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixoMFjun5hZe"
      },
      "outputs": [],
      "source": [
        "# TO COMPLETE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHFyGELx5hZe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPb2D3az5hZe"
      },
      "source": [
        "### Overall quality [5 marks]\n",
        "\n",
        "See the top of the notebook for submission instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PK_S95Rk5hZf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "134e43b2b54d45e7b74dea1979289395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a8c1891e70f40eba0c5dd002ad8d80e",
              "IPY_MODEL_0b26c14ae9724844af561cdf8c8e6264",
              "IPY_MODEL_aef137f9ae85403694df037ef06d8154"
            ],
            "layout": "IPY_MODEL_0e245b0e25f84912b4fc100241210511"
          }
        },
        "9a8c1891e70f40eba0c5dd002ad8d80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cbc5413acb947aba16198bca13ee5c7",
            "placeholder": "",
            "style": "IPY_MODEL_8e34bfcbc094420ba4300ec5f9c4a357",
            "value": "100%"
          }
        },
        "0b26c14ae9724844af561cdf8c8e6264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51aff0bb5d1d48df9cfdda9e201eb464",
            "max": 241627721,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72cedbcd1fb04e3cb03f6593c64effd7",
            "value": 241627721
          }
        },
        "aef137f9ae85403694df037ef06d8154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4152b8f51b9a456ab8d2d609e93cd3c1",
            "placeholder": "",
            "style": "IPY_MODEL_2e81a80bee1749c4938ded84075591bb",
            "value": " 230M/230M [00:03&lt;00:00, 53.4MB/s]"
          }
        },
        "0e245b0e25f84912b4fc100241210511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cbc5413acb947aba16198bca13ee5c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e34bfcbc094420ba4300ec5f9c4a357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51aff0bb5d1d48df9cfdda9e201eb464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72cedbcd1fb04e3cb03f6593c64effd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4152b8f51b9a456ab8d2d609e93cd3c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e81a80bee1749c4938ded84075591bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}